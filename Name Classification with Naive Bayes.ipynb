{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Classification with Naive Bayes\n",
    "\n",
    "## Overview\n",
    "\n",
    "Focus of this project is to build a python module, that can determine if a person is Japanese or not, based on their name string. \n",
    "Final product is a class file containing `NameClassifier` class, capable of \n",
    "- loading & preprocessing train and test data\n",
    "- train the model\n",
    "- predict and evaluate the model\n",
    "- save & load trained model for future use\n",
    "\n",
    "The data of name strings with various origin from the world was obtained by using `Faker` library in python. 100000 fake names were created for each class for training and testing purposes. \n",
    "\n",
    "## Libraries / Dependencies\n",
    "\n",
    "Couple python libraries were used to build this class\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- pickle\n",
    "\n",
    "In order to use the class, these libraries and their dependencies need to be installed on your system.\n",
    "\n",
    "## Setup and Locations\n",
    "\n",
    "This class is only tested on Ubuntu Linux 18.04 version, and can be used by importing the class. The class file `model.py` needs to be located in the directory where you intend to use it. Data and saved model file can be located anywhere, as long as you have relative path to them from the class file. However generally it's good idea to keep everything within same or its child's directory. \n",
    "\n",
    "Now the basics are all out of the way, let's get started!\n",
    "\n",
    "## Taking a look at data\n",
    "\n",
    "This module load in the name data as csv file using pandas. You should have separate csv files, each for Japanese and non-Japanese names. \n",
    "\n",
    "In a file, this would look like\n",
    "\n",
    ">Country, Address, name, other col..<br>\n",
    "value1, value2, John Smith, value4\n",
    "\n",
    "**As long as there are column named `name`, other columns won't be a problem.<br> \n",
    "There should always be a white space between first and last name though.**\n",
    "\n",
    "For example, using dataframe, the data might look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese Names: \n",
      "         code    name\n",
      "65086  jp_JP    田辺 稔\n",
      "80397  jp_JP   高橋 涼平\n",
      "98682  jp_JP   加納 健一\n",
      "81025  jp_JP   宇野 明美\n",
      "74745  jp_JP   杉山 直子\n",
      "7759   jp_JP    中島 稔\n",
      "68173  jp_JP  田辺 さゆり\n",
      "12969  jp_JP   高橋 太一\n",
      "81645  jp_JP   田辺 康弘\n",
      "94883  jp_JP   廣川 里佳\n",
      "\n",
      "non-Japanese Names:\n",
      "         code                        name\n",
      "31089  es_ES      Alvaro Valencia Bernat\n",
      "27573  en_US                James George\n",
      "15361  en_AU           Alexandra Schmidt\n",
      "78193  ru_RU  Антонов Аверьян Георгиевич\n",
      "75810  ru_RU     Самойлов Иван Архипович\n",
      "71612  ro_RO                 Savina Niță\n",
      "65742  pt_BR            Bernardo Peixoto\n",
      "64837  pl_PL           Leonard Matejczyk\n",
      "56023  no_NO                 Tom Eriksen\n",
      "27458  en_US             Victoria Cooley\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "j_name = pd.read_csv('data/jp_names.csv')\n",
    "f_name = pd.read_csv('data/f_names.csv')\n",
    "\n",
    "print(\"Japanese Names: \\n\", j_name.sample(10))\n",
    "print(\"\\nnon-Japanese Names:\\n\", f_name.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Preprocessing of data is one of the most important aspect of machine learing. It can boost or ruin the models' performance. \n",
    "Here, since we're dealing with text data, it needs to be encoded into numbers. \n",
    "\n",
    "### Spliting Dataset\n",
    "The dataset is splitted into train and test datasets, for model training and testing.\n",
    "Default ratio is set to \n",
    "> train : test = 70% : 30%\n",
    "\n",
    "This ratio can be modified if necessary.\n",
    "\n",
    "We use `NameClassifier.load_data()` method to load the data and split them into 2 dataset like this...\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name data: \n",
      " 79265    Козлова Полина Павловна\n",
      "56400                       石田 幹\n",
      "45059             Zelida Ferrara\n",
      "69150            Mariana Costela\n",
      "3966              Donna Robinson\n",
      "37636                       笹田 淳\n",
      "58805               Roger Bakken\n",
      "59723               Sander Strøm\n",
      "4612                        宮沢 淳\n",
      "65747                      青田 真綾\n",
      "Name: name, dtype: object\n",
      "\n",
      "labels:  [0 1 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "## import the class\n",
    "from model import NameClassifier\n",
    "\n",
    "# the method will return x_train, x_test, y_train, y_test in the particular order\n",
    "x_train, x_test, y_train, y_test = NameClassifier.load_data('data/jp_names.csv', 'data/f_names.csv', test_size=0.4)\n",
    "print('name data: \\n', x_train.sample(10))\n",
    "print('\\nlabels: ', y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Model\n",
    "In this simple technique, each word that appear in the dataset are assigned with unique number, so that each text can be expressed as a sequence of the numbers.\n",
    "The sequences are converted into vector with each position / index representing each word, and value expressing the frequency of the occurence of the word.\n",
    "\n",
    "<br>\n",
    "Specifically in this class, word count is utilized with scikit-learn's `CountVectorizer`. \n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "The data will be encoded into numpy sparse matrix, and is ready to be fed into the Naive Bayes model\n",
    "\n",
    "\n",
    "## How Naive Bayes works...\n",
    "\n",
    "Brah Brah....\n",
    "\n",
    "Using `Sklearn.naive_bayes.MultinomialNB` class.\n",
    "\n",
    "Encoding names with word count and traning naive bayes are done in `NameClassifer.train()` method, lile...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the vectorizer and training the model...\n",
      "training completed!\n"
     ]
    }
   ],
   "source": [
    "# First, instantiate the NameClassifer with your choice of name.\n",
    "clf = NameClassifier()\n",
    "\n",
    "# then start training with the training data\n",
    "clf.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Model evaluation was done by testset, with 3 metrics.\n",
    "### accuracy\n",
    "how many data points did the model correclty predicted, regardless of class\n",
    "\n",
    "$$acc = \\frac{TP + TN}{Total Data}$$\n",
    "\n",
    "### precision\n",
    "Out of all predicted Japanese names, how many were actually Japanese names?\n",
    "\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "### recall\n",
    "Out of all actual Japanese names, how many did we predict as Japanese?\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "By using `NameClassifier.evaluate()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.81125%\n",
      "precision: 1.0\n",
      "recall: 0.9962269808350616\n"
     ]
    }
   ],
   "source": [
    "# with test data, this will calculate each metrics, and return a dictionary\n",
    "metrics = clf.evaluate(x_test, y_test)\n",
    "\n",
    "print('accuracy: {}%\\nprecision: {}\\nrecall: {}'.format(metrics['accuracy']*100, metrics['precision'], metrics['recall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading the Model\n",
    "\n",
    "- Saving the trained model is easy, just use `NameClassifier.save_model()`\n",
    "- Loading can be done by `NameClassifier.load_model()`\n",
    "\n",
    "Both methods accept `path/to/modelFile/fileName.pickle` as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('saved_model.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

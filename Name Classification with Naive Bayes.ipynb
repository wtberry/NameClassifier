{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Classification with Naive Bayes\n",
    "\n",
    "## Overview\n",
    "\n",
    "Focus of this project is to build a python module, that can determine if a person is Japanese or not, based on their name string. \n",
    "Final product is a class file containing `NameClassifier` class, capable of \n",
    "- loading & preprocessing train and test data\n",
    "- train the model\n",
    "- predict and evaluate the model\n",
    "- save & load trained model for future use\n",
    "\n",
    "The data of name strings with various origin from the world was obtained by using `Faker` library in python. 100000 fake names were created for each class for training and testing purposes. \n",
    "\n",
    "## Libraries / Dependencies\n",
    "\n",
    "Couple python libraries were used to build this class\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- pickle\n",
    "\n",
    "In order to use the class, these libraries and their dependencies need to be installed on your system.\n",
    "\n",
    "## Setup and Locations\n",
    "\n",
    "This class is only tested on Ubuntu Linux 18.04 version, and can be used by importing the class. The class file `model.py` needs to be located in the directory where you intend to use it. Data and saved model file can be located anywhere, as long as you have relative path to them from the class file. However generally it's good idea to keep everything within same or its child's directory. \n",
    "\n",
    "Now the basics are all out of the way, let's get started!\n",
    "\n",
    "## Taking a look at data\n",
    "\n",
    "This module load in the name data as csv file using pandas. You should have separate csv files, each for Japanese and non-Japanese names. \n",
    "\n",
    "In a file, this would look like\n",
    "\n",
    ">Country, Address, name, other col..<br>\n",
    "value1, value2, John Smith, value4\n",
    "\n",
    "**As long as there is a column named `name` with the name data, other columns can also be present.<br> \n",
    "There should always be a white space between first and last name, since the model breaks down into first and last name, and analyze them.**\n",
    "\n",
    "For example, using dataframe, the data might look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese Names: \n",
      "         code    name\n",
      "28320  jp_JP   伊藤 加奈\n",
      "93197  jp_JP   中島 加奈\n",
      "83717  jp_JP   田辺 直人\n",
      "26733  jp_JP    鈴木 舞\n",
      "58254  jp_JP  野村 あすか\n",
      "77565  jp_JP   吉本 千代\n",
      "58693  jp_JP   青田 直子\n",
      "38966  jp_JP   山口 千代\n",
      "77998  jp_JP  大垣 聡太郎\n",
      "73452  jp_JP    小林 幹\n",
      "\n",
      "non-Japanese Names:\n",
      "         code                           name\n",
      "28559  en_US                     Roger Kemp\n",
      "80017  tr_TR  Zebirce Ayasun Hançer Dumanlı\n",
      "838    ar_EG                 Tyler Reynolds\n",
      "71633  ro_RO                  Adriana Dobre\n",
      "49043  it_IT                    Danny Ricci\n",
      "56978  no_NO                    Aud Arnesen\n",
      "36306  es_MX     Wilfrido Claudia Contreras\n",
      "25864  en_US                Christina Ellis\n",
      "68169  pt_BR          Maria Cecília da Rosa\n",
      "74183  ro_RO              Georgian Ardelean\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "j_name = pd.read_csv('data/jp_names.csv')\n",
    "f_name = pd.read_csv('data/f_names.csv')\n",
    "\n",
    "print(\"Japanese Names: \\n\", j_name.sample(10))\n",
    "print(\"\\nnon-Japanese Names:\\n\", f_name.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Preprocessing of data is one of the most important aspect of machine learing. It can boost or ruin the models' performance. \n",
    "Here, since we're dealing with text data, it needs to be encoded into numbers.\n",
    "\n",
    "### Spliting Dataset\n",
    "The dataset is splitted into train and test datasets, for model training and testing.\n",
    "Default ratio is set to \n",
    "> train : test = 70% : 30%\n",
    "\n",
    "This ratio can be modified if necessary.\n",
    "\n",
    "We use `NameClassifier.load_data()` method to load the data and split them into 2 dataset like this...\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name data: \n",
      " 52714               이 영숙\n",
      "16092     Matthew Wilson\n",
      "89334    Юстим Кириленко\n",
      "55628               山本 淳\n",
      "52764               박 정식\n",
      "546          David Bowen\n",
      "54600              青山 拓真\n",
      "24620              村山 裕樹\n",
      "92000               詹 金凤\n",
      "37699               杉山 舞\n",
      "Name: name, dtype: object\n",
      "\n",
      "labels:  [0. 1. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "## import the class\n",
    "from model import NameClassifier\n",
    "\n",
    "clf = NameClassifier()\n",
    "# the method will return x_train, x_test, y_train, y_test in the particular order\n",
    "x_train, x_test, y_train, y_test = clf.load_data(['data/jp_names.csv', 'data/f_names.csv'], test_size=0.4)\n",
    "print('name data: \\n', x_train.sample(10))\n",
    "print('\\nlabels: ', y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Model\n",
    "In this simple technique, each word that appear in the dataset are assigned with unique number, so that each text can be expressed as a sequence of the numbers.\n",
    "The sequences are converted into vector with each position / index representing each word, and value expressing the frequency of the occurence of the word.\n",
    "\n",
    "<br>\n",
    "Specifically in this class, word count is utilized with scikit-learn's `CountVectorizer`. \n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "The data will be encoded into numpy sparse matrix, and is ready to be fed into the Naive Bayes model\n",
    "<br>\n",
    "\n",
    "Also, this class is implemented using Naive Bayes algorithm, using `Sklearn.naive_bayes.MultinomialNB` class.\n",
    "\n",
    "Encoding names with word count and traning naive bayes are done in `NameClassifer.train()` method, lile...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the vectorizer and training the model...\n",
      "training completed!\n"
     ]
    }
   ],
   "source": [
    "# First, instantiate the NameClassifer with your choice of name.\n",
    "clf = NameClassifier()\n",
    "\n",
    "# then start training with the training data\n",
    "clf.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Model evaluation was done by testset, with 3 metrics.\n",
    "### accuracy\n",
    "how many data points did the model correclty predicted, regardless of class\n",
    "\n",
    "$$acc = \\frac{TP + TN}{Total Data}$$\n",
    "\n",
    "### precision\n",
    "Out of all predicted Japanese names, how many were actual Japanese names?\n",
    "\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "### recall\n",
    "Out of all actual Japanese names, how many did we predict as Japanese?\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "By using `NameClassifier.evaluate()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.35875%\n",
      "precision: 1.0\n",
      "recall: 0.967300077204692\n"
     ]
    }
   ],
   "source": [
    "# with test data, this will calculate each metrics, and return a dictionary\n",
    "metrics = clf.evaluate(x_test, y_test)\n",
    "#print(metrics)\n",
    "print('accuracy: {}%\\nprecision: {}\\nrecall: {}'.format(metrics['accuracy']*100, metrics['precision'][0], metrics['recall'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "**Testing Set**<br>\n",
    "Now let us predict some fake names, using the trained model. This can be done through `NameClassifier.predict()` method, and it accept python list of name strings. <br>\n",
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "some_names = ['渡辺　謙', '木村　拓哉', 'Jack Nicholson', ' 陳　港生']\n",
    "# Only the first 2 are Japanese name, so output should look like [1,1,0,0]\n",
    "pred = clf.predict(some_names)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output will be 1 for Japanese name, and 0 for non-Japanese name.<br> \n",
    "As you can see, it's getting everything right except it is predicting the last Chinese name as Japanese. \n",
    "\n",
    "\n",
    "### What about unseen names?\n",
    "\n",
    "\n",
    "Here, let's try to predict with names that were not existing in the training dataset, such as\n",
    "- unseen last / first names\n",
    "- Japanese Names in roman\n",
    "- non-Japanese names in Katakana\n",
    "\n",
    "Here we'll use the name 安倍晋三 as a test name, which is not included in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "\n",
      "So the name 安倍　晋三 is was not present in the training set.\n",
      "Let us try along with Katakana name.\n",
      "[1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# First we'll get word_dictionary that are based on model's training data\n",
    "trained_dict = clf.get_word_dict()\n",
    "print('安倍' in trained_dict.keys())\n",
    "print('晋三' in trained_dict.keys())\n",
    "\n",
    "print('\\nSo the name 安倍　晋三 is was not present in the training set.\\nLet us try along with Katakana name.')\n",
    "pred_anom = clf.predict(['安倍　晋三', 'ジェニファー　ローレンス', 'Jennifer Lawrence', 'Wataru Takahashi'])\n",
    "print(pred_anom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, model fails to recognize the Japanese name at index = 0. Possible improvement would be to \n",
    "- add more varieties to the training data\n",
    "- different ML algorithm\n",
    "\n",
    "## Saving and Loading the Model\n",
    "\n",
    "- Saving the trained model is easy, just use `NameClassifier.save_model()`\n",
    "- Loading can be done by `NameClassifier.load_model()`\n",
    "\n",
    "Both methods accept `path/to/modelFile/fileName.pickle` as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('saved_model.pickle')\n",
    "clf.load_model('saved_model.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do / future features\n",
    "\n",
    "- document the code better\n",
    "- Multi class classification of names for nationalities/origins -> on other branch\n",
    "- trying out with different algorithms, such as \n",
    "    - Neural nets (RNN?)\n",
    "    - random forest\n",
    "    - SVM\n",
    "- input the names as image data, and use CNN to train it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
